{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae5ce43f",
   "metadata": {},
   "source": [
    "# Notch Pass Filter Analysis\n",
    "\n",
    "In this notebook, we perform an analysis using a notch pass filter on the raw\n",
    "ECG data. For each subject, we remove a particular frequency from the raw signal\n",
    "and get the predicted age. We then calculate the MSE of the predicted age from\n",
    "the predicted age using the full signal. In cases where the information from the\n",
    "suppressed frequency is high, we expect a larger MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4eb9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "from resnet import ResNet1d\n",
    "import tqdm\n",
    "import h5py\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafa2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raw configuration and model data, as well as\n",
    "# the exam metadata and raw ECG signals.\n",
    "\n",
    "from constants import (\n",
    "    DATA_DIR,\n",
    "    N_LEADS,\n",
    ")\n",
    "config = '../model/config.json'\n",
    "\n",
    "# Instantiate the model using the config.json information.\n",
    "with open(config, 'r') as f:\n",
    "    config_dict = json.load(f)\n",
    "model = ResNet1d(\n",
    "    input_dim=(N_LEADS, config_dict['seq_length']),\n",
    "    blocks_dim=list(zip(config_dict['net_filter_size'], config_dict['net_seq_lengh'])),\n",
    "    n_classes=1,\n",
    "    kernel_size=config_dict['kernel_size'],\n",
    "    dropout_rate=config_dict['dropout_rate']\n",
    ")\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Retrieve the state dict, which has all the coefficients\n",
    "state_dict = (torch.load('../model/model.pth',\n",
    "              weights_only=False,\n",
    "              map_location=device))\n",
    "\n",
    "# Load the state dict and set the model to eval mode.\n",
    "model.load_state_dict(state_dict['model'])\n",
    "model.eval()\n",
    "\n",
    "# Read in exam metadata and limit to file 16.\n",
    "df = pd.read_csv(f'{DATA_DIR}/exams.csv')\n",
    "df = df[df['trace_file'] == 'exams_part16.hdf5']\n",
    "\n",
    "# Read in raw ECG data for file 16.\n",
    "filename = \"../data/exams_part16.hdf5\"\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    print(\"Keys in the HDF5 file:\", list(f.keys()))\n",
    "    dataset = f['tracings']\n",
    "    print(\"Dataset shape:\", dataset.shape)\n",
    "    print(\"Dataset dtype:\", dataset.dtype)\n",
    "    data_array = f['tracings'][()]\n",
    "    exam_ids = f['exam_id'][()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40197805",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5625c709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out the notch filtering. We should get an output signal that is\n",
    "# somewhata similar to the raw signal with only minor changes\n",
    "\n",
    "samp_freq = 409.6  # Sample frequency (Hz)\n",
    "notch_freq = 50.0  # Frequency to be removed from signal (Hz)\n",
    "quality_factor = 20.0  # Quality factor\n",
    "b_notch, a_notch = signal.iirnotch(notch_freq, quality_factor, samp_freq)\n",
    "outputSignal = signal.filtfilt(b_notch, a_notch, data_array[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9bd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(data_array[0, :, 0])\n",
    "plt.plot(outputSignal)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2ed92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the frequencies. For each frequency, use a notch pass\n",
    "# on the first n_total subjects (all channels) and see how much the\n",
    "# predicted ages differ from the raw predicted ages (as measured by\n",
    "# MSE).\n",
    "\n",
    "samp_freq = 409.6  # Sample frequency (Hz)\n",
    "quality_factor = 20.0  # Quality factor\n",
    "\n",
    "n_total = 100  # total number of predictions\n",
    "batch_size = 10\n",
    "n_batches = int(np.ceil(n_total/batch_size))\n",
    "\n",
    "data_array_trans = np.zeros([n_total, data_array.shape[1], data_array.shape[2]])\n",
    "\n",
    "mse = []\n",
    "for freq in range(2, 50):\n",
    "    print(freq)\n",
    "    notch_freq = freq  # Frequency to be removed from signal (Hz)\n",
    "    b_notch, a_notch = signal.iirnotch(notch_freq, quality_factor, samp_freq)\n",
    "    for i in range(n_total):\n",
    "        for j in range(data_array.shape[2]):\n",
    "            data_array_trans[i, :, j] = signal.filtfilt(b_notch, a_notch, data_array[i, :, j])\n",
    "    \n",
    "    pred_list = []\n",
    "    predicted_age = np.zeros((n_total,))\n",
    "    end = 0\n",
    "    for i in tqdm.tqdm(range(n_batches)):\n",
    "        start = end\n",
    "        end = min((i + 1) * batch_size, n_total)\n",
    "\n",
    "        # Get the predictions\n",
    "\n",
    "        model.zero_grad()\n",
    "        y_pred = model(torch.tensor(data_array_trans[start:end, :, :], dtype=torch.float).transpose(-1, -2))\n",
    "\n",
    "        # Merge predictions back onto the metadata frame\n",
    "        preds = pd.DataFrame({'exam_id': exam_ids[start:end],\n",
    "                              'torch_pred': y_pred.detach().numpy().squeeze()})\n",
    "        predicted_age[start:end] = y_pred.detach().cpu().numpy().flatten()\n",
    "        pred_list.append(preds)\n",
    "\n",
    "    preds = pd.concat(pred_list, axis=0, ignore_index=True)\n",
    "    compare = df.merge(preds, on='exam_id', how='inner')\n",
    "    mse.append(float(np.mean((compare['nn_predicted_age'] - compare['torch_pred'])**2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be318f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot frequency against MSE\n",
    "plt.plot(np.arange(2, len(mse) + 2), mse)\n",
    "plt.xlabel('Frequency')\n",
    "plt.ylabel('MSE')\n",
    "plt.savefig('../output/images/frequency_vs_mse.png')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0813b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecg_precise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
